[package]
name = "llm-test-bench-core"
version.workspace = true
edition.workspace = true
license.workspace = true
authors.workspace = true
repository.workspace = true
homepage.workspace = true
documentation.workspace = true
keywords.workspace = true
categories.workspace = true
rust-version.workspace = true
description = "Core library for LLM Test Bench - comprehensive testing framework for Large Language Models with 65+ supported models across 14+ providers"
readme = "../README.md"

[dependencies]
# Async runtime
tokio = { workspace = true }

# HTTP client
reqwest = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = { workspace = true }
serde_yaml = "0.9"

# Configuration
config = { workspace = true }
toml = { workspace = true }

# Error handling
anyhow = { workspace = true }
thiserror = { workspace = true }

# Logging
tracing = { workspace = true }

# Async trait support
async-trait = "0.1"

# Validation
serde_valid = { version = "0.20" }

# Utilities
dirs = "5.0"  # For finding config directories
chrono = { version = "0.4", features = ["serde"] }  # Timestamps
futures = "0.3"  # Stream utilities
reqwest-eventsource = "0.6"  # SSE streaming
pin-project = "1.1"  # Pin projection for custom streams
lru = "0.12"  # LRU cache for evaluation results
siphasher = "1.0"  # Fast hashing for cache keys

# Benchmarking
indicatif = { workspace = true }  # Progress bars
csv = { workspace = true }  # CSV export

# Statistical analysis
statrs = "0.17"  # Statistical functions

# Visualization
tera = "1.20"  # Template engine

# Text analysis
unicode-segmentation = "1.11"  # Text tokenization
regex = "1.10"  # Pattern matching for discourse markers

# Multi-modal support
base64 = "0.21"  # Base64 encoding/decoding for images and audio

# Real-time monitoring
prometheus = "0.13"  # Prometheus metrics export
axum = { version = "0.7", features = ["ws", "macros"] }  # Web framework with WebSocket support
tower = "0.4"  # Middleware and service utilities
tower-http = { version = "0.5", features = ["cors", "trace", "compression-full"] }  # HTTP middleware
tokio-tungstenite = "0.21"  # WebSocket protocol
parking_lot = "0.12"  # High-performance synchronization primitives

# Plugin system (WASM)
wasmtime = "19.0"  # WASM runtime
wasmtime-wasi = "19.0"  # WASI support for plugins
serde_bytes = "0.11"  # Efficient byte serialization for plugin communication

# API server
async-graphql = { version = "7.0", features = ["chrono"] }  # GraphQL implementation
async-graphql-axum = "7.0"  # GraphQL integration with Axum
utoipa = { version = "4.2", features = ["axum_extras"] }  # OpenAPI documentation
utoipa-swagger-ui = { version = "6.0", features = ["axum"] }  # Swagger UI
jsonwebtoken = "9.2"  # JWT authentication
bcrypt = "0.15"  # Password hashing
tower_governor = "0.4"  # Rate limiting
uuid = { version = "1.7", features = ["v4", "serde"] }  # UUID generation

# Distributed architecture
tonic = "0.11"  # gRPC framework
prost = "0.12"  # Protocol buffers
tokio-stream = "0.1"  # Async stream utilities
dashmap = "5.5"  # Concurrent hash map
crossbeam = "0.8"  # Concurrent data structures and channels
num_cpus = "1.16"  # CPU core detection

# Database backend (PostgreSQL) - optional
sqlx = { version = "0.7", features = ["runtime-tokio", "postgres", "chrono", "uuid", "json", "migrate"], optional = true }

# Datasets integration
llm-test-bench-datasets = { version = "0.1.0", path = "../datasets" }

# === LLM Dev Ops Infra Integration (Phase 2B - ACTIVE) ===
# Foundation Layer (Layer 0) - Error handling
infra-errors = { workspace = true, optional = true }

# Utilities Layer (Layer 1) - Config, JSON, Crypto, ID
infra-config = { workspace = true, optional = true }
infra-json = { workspace = true, optional = true }
infra-crypto = { workspace = true, optional = true }
infra-id = { workspace = true, optional = true }

# Services Layer (Layer 2) - Observability, HTTP, FS, Schema, Simulation, Audit
infra-otel = { workspace = true, optional = true }
infra-http = { workspace = true, optional = true }
infra-fs = { workspace = true, optional = true }
infra-schema = { workspace = true, optional = true }
infra-sim = { workspace = true, optional = true }
infra-audit = { workspace = true, optional = true }

# Application Layer (Layer 3) - Vector operations, Auth
infra-vector = { workspace = true, optional = true }
infra-auth = { workspace = true, optional = true }

# LLM-Specific Layer (Phase 2B) - Retry, Cache, Rate-Limit, LLM Client
infra-retry = { workspace = true, optional = true }
infra-cache = { workspace = true, optional = true }
infra-rate-limit = { workspace = true, optional = true }
infra-llm-client = { workspace = true, optional = true }

# === Upstream Integration Dependencies (Phase 2B) ===
# Provider SDKs
async-openai = { workspace = true, optional = true }
hf-hub = { workspace = true, optional = true }
ollama-rs = { workspace = true, optional = true }

# Observability (legacy - use infra-otel for new code)
opentelemetry = { workspace = true, optional = true }
opentelemetry-semantic-conventions = { workspace = true, optional = true }
opentelemetry-otlp = { workspace = true, optional = true }
tracing-opentelemetry = { workspace = true, optional = true }

# Evaluation Frameworks
pyo3 = { workspace = true, optional = true }

# Multi-Modal
image = { workspace = true, optional = true }
imageproc = { workspace = true, optional = true }
rodio = { workspace = true, optional = true }
hound = { workspace = true, optional = true }
symphonia = { workspace = true, optional = true }

# Storage
lance = { workspace = true, optional = true }
qdrant-client = { workspace = true, optional = true }
redis = { workspace = true, optional = true }

# Security & Privacy
secrecy = { workspace = true, optional = true }

# === LLM Dev Ops Suite Integration Dependencies (Phase 2B) ===
# NOTE: These dependencies are commented out until the crates are published to crates.io
# When available, uncomment the dependencies below and enable corresponding features
# The feature flags remain active for structural preparation

# Observability & Monitoring
# llm-observatory = { workspace = true, optional = true }
# llm-latency-lens = { workspace = true, optional = true }
# llm-sentinel = { workspace = true, optional = true }

# Configuration & Schema
# llm-schema-registry = { workspace = true, optional = true }
# llm-config-manager = { workspace = true, optional = true }

# Integration & Connectivity
# llm-connector-hub = { workspace = true, optional = true }
# llm-inference-gateway = { workspace = true, optional = true }

# Security & Policy
# llm-shield = { workspace = true, optional = true }
# llm-policy-engine = { workspace = true, optional = true }

# Memory & Storage
# llm-memory-graph = { workspace = true, optional = true }
# llm-data-vault = { workspace = true, optional = true }

# Development & Testing
# llm-forge = { workspace = true, optional = true }
# llm-simulator = { workspace = true, optional = true }
# llm-benchmark-exchange = { workspace = true, optional = true }

# Operations & Optimization
# llm-auto-optimizer = { workspace = true, optional = true }
# llm-incident-manager = { workspace = true, optional = true }
# llm-cost-ops = { workspace = true, optional = true }
# llm-orchestrator = { workspace = true, optional = true }

# Governance & Registry
# llm-governance-dashboard = { workspace = true, optional = true }
# llm-registry = { workspace = true, optional = true }

# Marketplace & Analytics
# llm-marketplace = { workspace = true, optional = true }
# llm-analytics-hub = { workspace = true, optional = true }

# AI Assistance
# llm-copilot-agent = { workspace = true, optional = true }

# Advanced Features
# llm-edge-agent = { workspace = true, optional = true }
# llm-research-lab = { workspace = true, optional = true }

[features]
default = []

# Existing features
database = ["sqlx"]

# === LLM Dev Ops Infra Features (Phase 2B - ACTIVE) ===
# Foundation Layer
infra-errors-feature = ["dep:infra-errors"]

# Utilities Layer
infra-config-feature = ["dep:infra-config", "infra-errors-feature"]
infra-json-feature = ["dep:infra-json", "infra-errors-feature"]
infra-crypto-feature = ["dep:infra-crypto", "infra-errors-feature"]
infra-id-feature = ["dep:infra-id", "infra-errors-feature"]

# Services Layer
infra-otel-feature = ["dep:infra-otel", "infra-errors-feature"]
infra-http-feature = ["dep:infra-http", "infra-errors-feature"]
infra-fs-feature = ["dep:infra-fs", "infra-errors-feature"]
infra-schema-feature = ["dep:infra-schema", "infra-errors-feature"]
infra-sim-feature = ["dep:infra-sim", "infra-errors-feature"]
infra-audit-feature = ["dep:infra-audit", "infra-errors-feature"]

# Application Layer
infra-vector-feature = ["dep:infra-vector", "infra-errors-feature"]
infra-auth-feature = ["dep:infra-auth", "infra-errors-feature"]

# LLM-Specific Layer (Phase 2B)
infra-retry-feature = ["dep:infra-retry", "infra-errors-feature"]
infra-cache-feature = ["dep:infra-cache", "infra-errors-feature"]
infra-rate-limit-feature = ["dep:infra-rate-limit", "infra-errors-feature"]
infra-llm-client-feature = ["dep:infra-llm-client", "infra-errors-feature", "infra-retry-feature", "infra-cache-feature", "infra-rate-limit-feature"]

# Infra Bundle Features
infra-core = [
    "infra-errors-feature",
    "infra-config-feature",
    "infra-otel-feature",
]

infra-testing = [
    "infra-sim-feature",
    "infra-errors-feature",
]

infra-full = [
    "infra-errors-feature",
    "infra-config-feature",
    "infra-json-feature",
    "infra-crypto-feature",
    "infra-id-feature",
    "infra-otel-feature",
    "infra-http-feature",
    "infra-fs-feature",
    "infra-schema-feature",
    "infra-sim-feature",
    "infra-audit-feature",
    "infra-vector-feature",
    "infra-auth-feature",
    "infra-retry-feature",
    "infra-cache-feature",
    "infra-rate-limit-feature",
    "infra-llm-client-feature",
]

# Infra LLM Bundle (Phase 2B) - All LLM-specific utilities
infra-llm = [
    "infra-errors-feature",
    "infra-retry-feature",
    "infra-cache-feature",
    "infra-rate-limit-feature",
    "infra-llm-client-feature",
]

# === Individual Provider Features ===
provider-google = []  # Implement via reqwest (no dedicated crate available)
provider-openai-extended = ["dep:async-openai"]
provider-huggingface = ["dep:hf-hub"]
provider-ollama = ["dep:ollama-rs"]
provider-cohere = []  # Implement via reqwest
provider-mistral = []  # Implement via reqwest
provider-together = []  # Implement via reqwest
provider-replicate = []  # Implement via reqwest
provider-vllm = []  # Implement via HTTP

# === Provider Bundle ===
all-providers = [
    "provider-google",
    "provider-openai-extended",
    "provider-huggingface",
    "provider-ollama",
    "provider-cohere",
    "provider-mistral",
    "provider-together",
    "provider-replicate",
    "provider-vllm",
]

# === Observability Features ===
observability-otel = [
    "dep:opentelemetry",
    "dep:opentelemetry-semantic-conventions",
    "dep:opentelemetry-otlp",
    "dep:tracing-opentelemetry",
]
observability-langsmith = []  # HTTP-based integration
observability-phoenix = []  # HTTP-based integration
observability-prometheus = []  # Already included in core

# === Observability Bundle ===
all-observability = [
    "observability-otel",
    "observability-langsmith",
    "observability-phoenix",
    "observability-prometheus",
]

# === Evaluation Features ===
eval-python-bindings = ["dep:pyo3"]
eval-ragas = ["eval-python-bindings"]
eval-deepeval = ["eval-python-bindings"]
eval-lm-harness = ["eval-python-bindings"]
eval-helm = ["eval-python-bindings"]

# === Evaluation Bundle ===
all-eval = [
    "eval-ragas",
    "eval-deepeval",
    "eval-lm-harness",
    "eval-helm",
]

# === Multi-Modal Features ===
multimodal-vision = ["dep:image", "dep:imageproc"]
multimodal-audio = ["dep:rodio", "dep:hound", "dep:symphonia"]
multimodal = ["multimodal-vision", "multimodal-audio"]

# === Storage Features ===
storage-lance = ["dep:lance"]
storage-vector = ["dep:qdrant-client"]
storage-redis = ["dep:redis"]
storage-advanced = ["storage-lance", "storage-vector", "storage-redis"]

# === Security Features ===
security-crypto = ["dep:secrecy"]
privacy-dp = ["security-crypto"]  # Differential privacy requires crypto

# === Enterprise Bundle ===
enterprise = [
    "database",
    "storage-advanced",
    "security-crypto",
    "privacy-dp",
]

# === Full Feature Set (Development/Testing) ===
full = [
    "all-providers",
    "all-observability",
    "all-eval",
    "multimodal",
    "enterprise",
]

# === CI/CD Feature (Common integrations only) ===
ci = [
    "provider-google",
    "provider-ollama",
    "observability-otel",
    "multimodal-vision",
]

# === LLM Dev Ops Suite Integration Features (Phase 2B) ===
# NOTE: Feature flags are ready for integration. When the dependencies are uncommented above,
# uncomment the corresponding "dep:" lines below to activate each integration.

# Observability & Monitoring Features
suite-observatory = [] # Enable: ["dep:llm-observatory"]
suite-latency-lens = [] # Enable: ["dep:llm-latency-lens"]
suite-sentinel = [] # Enable: ["dep:llm-sentinel"]

# Configuration & Schema Features
suite-schema-registry = [] # Enable: ["dep:llm-schema-registry"]
suite-config-manager = [] # Enable: ["dep:llm-config-manager"]

# Integration & Connectivity Features
suite-connector-hub = [] # Enable: ["dep:llm-connector-hub"]
suite-inference-gateway = [] # Enable: ["dep:llm-inference-gateway"]

# Security & Policy Features
suite-shield = [] # Enable: ["dep:llm-shield"]
suite-policy-engine = [] # Enable: ["dep:llm-policy-engine"]

# Memory & Storage Features
suite-memory-graph = [] # Enable: ["dep:llm-memory-graph"]
suite-data-vault = [] # Enable: ["dep:llm-data-vault"]

# Development & Testing Features
suite-forge = [] # Enable: ["dep:llm-forge"]
suite-simulator = [] # Enable: ["dep:llm-simulator"]
suite-benchmark-exchange = [] # Enable: ["dep:llm-benchmark-exchange"]

# Operations & Optimization Features
suite-auto-optimizer = [] # Enable: ["dep:llm-auto-optimizer"]
suite-incident-manager = [] # Enable: ["dep:llm-incident-manager"]
suite-cost-ops = [] # Enable: ["dep:llm-cost-ops"]
suite-orchestrator = [] # Enable: ["dep:llm-orchestrator"]

# Governance & Registry Features
suite-governance-dashboard = [] # Enable: ["dep:llm-governance-dashboard"]
suite-registry = [] # Enable: ["dep:llm-registry"]

# Marketplace & Analytics Features
suite-marketplace = [] # Enable: ["dep:llm-marketplace"]
suite-analytics-hub = [] # Enable: ["dep:llm-analytics-hub"]

# AI Assistance Features
suite-copilot-agent = [] # Enable: ["dep:llm-copilot-agent"]

# Advanced Features
suite-edge-agent = [] # Enable: ["dep:llm-edge-agent"]
suite-research-lab = [] # Enable: ["dep:llm-research-lab"]

# === Suite Bundle Features ===
suite-observability = [
    "suite-observatory",
    "suite-latency-lens",
    "suite-sentinel",
]

suite-config = [
    "suite-schema-registry",
    "suite-config-manager",
]

suite-integration = [
    "suite-connector-hub",
    "suite-inference-gateway",
]

suite-security = [
    "suite-shield",
    "suite-policy-engine",
]

suite-storage = [
    "suite-memory-graph",
    "suite-data-vault",
]

suite-development = [
    "suite-forge",
    "suite-simulator",
    "suite-benchmark-exchange",
]

suite-operations = [
    "suite-auto-optimizer",
    "suite-incident-manager",
    "suite-cost-ops",
    "suite-orchestrator",
]

suite-governance = [
    "suite-governance-dashboard",
    "suite-registry",
]

suite-marketplace-bundle = [
    "suite-marketplace",
    "suite-analytics-hub",
]

suite-advanced = [
    "suite-edge-agent",
    "suite-research-lab",
    "suite-copilot-agent",
]

# === All Suite Features ===
suite-all = [
    "suite-observability",
    "suite-config",
    "suite-integration",
    "suite-security",
    "suite-storage",
    "suite-development",
    "suite-operations",
    "suite-governance",
    "suite-marketplace-bundle",
    "suite-advanced",
]

[dev-dependencies]
tokio = { workspace = true, features = ["test-util"] }
predicates = { workspace = true }
tempfile = "3.10"  # For testing config file creation
wiremock = "0.6"  # HTTP mocking for unit tests
mockall = "0.13"  # Trait mocking

[lib]
name = "llm_test_bench_core"
path = "src/lib.rs"
